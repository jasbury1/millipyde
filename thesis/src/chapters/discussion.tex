\chapter{Conclusion and Discussion}

This thesis has presented the start to a Python GPU programming framework called Millipyde. Millipyde specializes in problems that involve many transformations are performed on array-like input data sets, as is the case with image augmentation. Millipyde also takes takes full advantage of multi-device scheduling in systems that contain more than one GPU. Python programmers who use Millipyde are given the flexibility to let the framework schedule tasks across the available devices, or they can take the reigns themselves with specifying the target device in a variety of situations. Finally, Millipyde was designed in AMD's ROCm platform from the ground up with the goal of providing cross-platform support. 

\quad Millipyde provides two new types for Python programmers -- the gpuarray and the gpuimage. In order to maintain as much compatibility as possible in a complicated landscape of existing Python tools and libraries, these types aim to be fully compatible with NumPy ndarrays and related types such as SciPy's ndimage. Each of these types can be used with a variety of individual functions that take advantage of GPU acceleration. Millipyde also provides execution constructs, the Operation, Pipeline, and the Generator, that allow users to transform data in a variety of ways. Each of these constructs also allows for different scheduling patterns using the available devices on the system.

\quad Our benchmarks showed a lot of promise with Millipyde's performance. The some of the GPU-accelerated functions were able to perform up to tens to hundreds of times faster than their respective CPU variants depending on the task and the size of the input. From there, further acceleration can be achieved by taking advantage of all resources available on the system. Constructs such as the Pipeline can exploit multiple levels of GPU parallelism by using streams on individual GPUs and transferring work across multiple GPUs. In some cases, the performance benefits were less than expected and sometimes resulted in strange benchmarking patterns. More work needs to be done to analyze the program execution in these cases to look for unexpected bottlenecks or data dependencies. More work also needs to be done on experimenting with data types. It's possible that alternative types such as smaller floating point and reducing type conversions values might have improve performance for some functions.

\quad Overall, ROCm proved itself to be a flexible and powerful choice for Millipyde's development. The benefits to cross-platform development are undeniable, and we hope that this becomes the norm for GPU tools and ecosystems going forward. The open nature of the ROCm community allowed us to track down many implementation nuances, bugs, and future plans that may have been harder to find in a closed ecosystem. We hope that AMD stays committed to its view of the future of GPGPU computing, and that more developers join this vision by contributing libraries to the ROCm ecosystem. 

\quad The use of ROCm was not without downsides, however. Due to its infancy, the tools available may not be as powerful as equivalents in environments such as CUDA. One area this showed the most was with benchmarking and profiling. The current profilers proved difficult to use and hard to parse, so we hope that this area gets more attention from developers going forwards.

